{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kpalaha/Naive_Bayes_Spam_Email_Detection/blob/main/CA02_NB_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCZYXwtCsL_y"
      },
      "source": [
        "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm.\n",
        "\n",
        "In this assignment you will ...\n",
        "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
        "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
        "\n",
        "IMPORTANT NOTE:\n",
        "\n",
        "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4p_DvtT7sOIr",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f4986d-c515-4fc7-feb9-869dc62ee189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install os\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Import all other necessary libraries. Your code below ...\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8I1_vVJX6fVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jjKF0nIMwz8_",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "#Lauryn Carter\n",
        "def make_Dictionary(root_dir):\n",
        "#Creating a function make_Dictionary using the parameter root_dir. This parameter allows the function to read the text files from the root directory.\n",
        "  all_words = []\n",
        "  #Creating a list called all_words\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] #This line goes through each text file and their paths, and puts them in the root directory (root_dir). They are all stored in a LIST, called emails.\n",
        "  for mail in emails: #Using a for loop to reiterate through each text file/email in emails\n",
        "    with open(mail) as m: #This line opens one of the emails and assigns it to m\n",
        "      for line in m: #Using a for loop to go through each line in the email\n",
        "        words = line.split() #This line of code splits each line into multiple words and assigns each word to the variable words\n",
        "        all_words += words #Adding each word to a list called all_words\n",
        "  dictionary = Counter(all_words) #Creating a dictionary of unique words using the Counter class\n",
        "  list_to_remove = list(dictionary) #Turns the dictionary into a list called list_to_remove\n",
        "\n",
        "  for item in list_to_remove: #Using a for loop for each word in list_to_remove\n",
        "    if item.isalpha() == False: #If statement that checks whether or not a word in the list contains a non-alpha character\n",
        "      del dictionary[item] #Deletes the word if it does contain a non-alpha character\n",
        "    elif len(item) == 1: #Else if the word is only one character long\n",
        "      del dictionary[item] #Delete the word if it is only one character long\n",
        "  dictionary = dictionary.most_common(3000) #This line of code counts how many times an item in the dictionary is listed. But it only asks for the most frequent 3000 words\n",
        "  return dictionary #Returns the most 3000 words in a tuple form\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dmVW5xNlyOFc",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "#Lauryn Carter\n",
        "def extract_features(mail_dir):\n",
        "#Creating a function extract_features using the parameter mail_dir.\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)] #Similar to root_dir this line goes through each text file and their paths, and puts them in the mail directory (mail_dir). They are all stored in a LIST, called files.\n",
        "  features_matrix = np.zeros((len(files),3000)) #Creating a numpy array of zeros whose row length is the number of files and 3000 columns\n",
        "  train_labels = np.zeros(len(files)) #Creating another numpy array of zeros whose row length is the number of files\n",
        "  count = 1; #Assign the value 1 to count\n",
        "  docID = 0; #Assign the value 0 to docID\n",
        "  for fil in files: #For loop for every file in files\n",
        "    with open(fil) as fi: #Opens each file\n",
        "      for i, line in enumerate(fi): #This line iterates over each line in the file\n",
        "        if i ==2: #If statement that checks if the file line is equal to two words,\n",
        "          words = line.split() #Then split the line into multiple words and assign it to the variable words\n",
        "          for word in words: #For loop, for each word in words\n",
        "            wordID = 0 #Assign the value 0 to wordID\n",
        "            for i, d in enumerate(dictionary): #This line iterates over each pair (the word and its count value)\n",
        "              if d[0] == word: #if the word/value pair is equal to the word\n",
        "                wordID = i #Assigns the index to the variable wordID\n",
        "                features_matrix[docID,wordID] = words.count(word) #This line of code assigns the count value to its place in the features_matrix. Also returns the count of the word in the words list\n",
        "      train_labels[docID] = 0; #Still in the for loop for fil in files, assigns the value 0 to the index docID of the train_labels array\n",
        "      filepathTokens = fil.split('/') #Creates tokens by splitting the file path using / as a delimiter\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1] #This line assigns lastToken to the last token of the filepathTokens by using the len method\n",
        "      if lastToken.startswith(\"spmsg\"): #If statement that says if the token starts with \"spmsg\",\n",
        "        train_labels[docID] = 1; #then assign the value 1 to it\n",
        "        count = count + 1 #Adds 1 to count to keep track of how many spam messages there are\n",
        "      docID = docID + 1 #Adds 1 to docID\n",
        "  return features_matrix, train_labels  #Returns the arrays features_matrix and train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoq-rE7Mx0pp",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "#Lauryn Carter\n",
        "# Enter the \"path\" of your \"train_mails\" and \"test-mails\" FOLDERS in this cell ...\n",
        "TRAIN_DIR = \"./train-mails\"\n",
        "TEST_DIR = \"./test-mails\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "134lmhauyQxE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "b3796a38-5429-4955-dfa8-fb2524f0c952"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train-mails'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2d3af3bae49d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Lauryn Carter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_Dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Using the make_Dictionary function using the training emails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"reading and processing emails from TRAIN and TEST folders\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Print out the string message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatures_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Use the extract_features function on the training emails and assign them to features_matrix and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-9532d2301a38>\u001b[0m in \u001b[0;36mmake_Dictionary\u001b[0;34m(root_dir)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#Creating a list called all_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0memails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#This line goes through each text file and their paths, and puts them in the root directory (root_dir). They are all stored in a LIST, called emails.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mmail\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memails\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Using a for loop to reiterate through each text file/email in emails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmail\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#This line opens one of the emails and assigns it to m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train-mails'"
          ]
        }
      ],
      "source": [
        "#Lauryn Carter\n",
        "dictionary = make_Dictionary(TRAIN_DIR) #Using the make_Dictionary function using the training emails\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\") #Print out the string message\n",
        "features_matrix, labels = extract_features(TRAIN_DIR) #Use the extract_features function on the training emails and assign them to features_matrix and labels\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR) #Use the extract_features function on the test emails and assign them to test_features_matrix and test_labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Gaussian Naive Bayes model\n",
        "model = GaussianNB() # create an instance of the model to be used for our programming\n",
        "print(\"reading and processing emails from TRAIN and TEST folders\") # print text to explain where we are in process\n",
        "\n",
        "print(\"Training Model using Gaussian Naive Bayes algorithm .....\") # print desired text to explain results\n",
        "model.fit(features_matrix, labels) # fit the data to the model instance we called\n",
        "print(\"Training completed\") # print text in results that training has been completed\n",
        "\n",
        "# Test the Model\n",
        "print(\"Testing trained model to predict Test Data labels\") # print text to show model will be tested\n",
        "y_predicted = model.predict(test_features_matrix) # predict labels using test features\n",
        "print(\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\") # show model has been completed, and accuracy score will be below\n",
        "print(accuracy_score(test_labels, y_predicted)) # print accuracy score of tested labels, against the labels that it should be"
      ],
      "metadata": {
        "id": "snqF3_5pIWD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHkWvB-x2FWP"
      },
      "outputs": [],
      "source": [
        "# In this section enter your code to TRAIN the model using Naive Bayes algorithm, then PREDICT and then evaluate PERFORMANCE (Accuracy)\n",
        "# Your code below ...\n",
        "#\n",
        "#\n",
        "#\n",
        "# Your output should look like below if your code is right"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_mPrvN586A"
      },
      "source": [
        "======================= END OF PROGRAM ========================="
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}